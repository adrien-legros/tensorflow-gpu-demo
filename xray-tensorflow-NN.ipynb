{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a294e7c42ce849d10ec8d41a3347a9496f5cde67"
   },
   "source": [
    "# Binary classification with Keras neural network running on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "736f330d37373a5a50072c5cd764c93f66e9fe82"
   },
   "source": [
    "Original notebook: https://www.kaggle.com/kosovanolexandr/keras-nn-x-ray-predict-pneumonia-86-54  \n",
    "Dataset: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\n",
    "\n",
    "### Our Goal\n",
    "\n",
    "The goal of this notebook is to demonstrate the GPU utilization on an Openshift Cluster with Open Data Hub components running on top of it.  \n",
    "Jupyter Notebook has been deployed by the Open Data Hub operator and this notebook image was build with all the dependencies needed to use GPU thanks to the operator. Especially we are working with tensorflow-gpu version 2.7.0 and Cuda version 11.4.2.  \n",
    "We will demonstrate the GPU usage by building a neural network. We will train a neural network with xrays of chests in order to predict if a patient suffers from a pneumonia.\n",
    "\n",
    "You can run this notebook cell by cell and see the ressource usage on the following Grafana: https://grafana-route-grafana.apps.sno-nvidia-p6.redhat.hpecic.net/dashboards/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e5b516ff56512bd7de9e0a1a5ee3b2cb64ed8323"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary packages for our python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3414a6501e086b4ae0c1e5e1d07c6063deb56a7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that GPU is enabled by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a device named */physical_device:GPU:0* has been discovered thanks to the dependencies installed with this notebook image. The type of this device is *GPU*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('List of available GPUs: ', tf.config.list_physical_devices('GPU'))\n",
    "print(\"Number of GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e668e47eadc515fac8b436f1afe550a60b6bc6ba"
   },
   "source": [
    "### Verify our directories structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a6fc32162ae1d0b163ed3f364035d0830bcc6584"
   },
   "outputs": [],
   "source": [
    "print(os.listdir(\"/opt/app-root/src/data/chest_xray\"))\n",
    "\n",
    "print(os.listdir(\"/opt/app-root/src/data/chest_xray/test\"))\n",
    "\n",
    "print(os.listdir(\"/opt/app-root/src/data/chest_xray/train/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check an image in the \"NORMAL\" training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display a random image from the normal training set i.e tagged as a patient without any pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f0cc54a0947052f0904611ce913fbb39d503a093"
   },
   "outputs": [],
   "source": [
    "img_name = 'NORMAL2-IM-0588-0001.jpeg'\n",
    "img_normal = load_img('/opt/app-root/src/data/chest_xray/train/NORMAL/' + img_name)\n",
    "\n",
    "print('NORMAL')\n",
    "plt.imshow(img_normal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check an image in the PNEUMONIA training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's display a random image from the pneumonia training set i.e tagged as a patient who suffers from a pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46397323a451df86eb2414bfeecb1e5fbc41a51d"
   },
   "outputs": [],
   "source": [
    "img_name = 'person63_bacteria_306.jpeg'\n",
    "img_pneumonia = load_img('/opt/app-root/src/data/chest_xray/train/PNEUMONIA/' + img_name)\n",
    "\n",
    "print('PNEUMONIA')\n",
    "plt.imshow(img_pneumonia)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9f7b082b32bbe84b8a58fe055a2db51fb31be5e0"
   },
   "source": [
    "### Initialize variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are defining few variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7b3d31411d932082af8199660bd47b6d6e4d7a4"
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "707187c665591bd285e646b99c2fef818de42ea6"
   },
   "outputs": [],
   "source": [
    "# Path to the data directories\n",
    "train_data_dir = '/opt/app-root/src/data/chest_xray/train'\n",
    "test_data_dir = '/opt/app-root/src/data/chest_xray/test'\n",
    "\n",
    "nb_train_samples = 5232 # Number of train images\n",
    "epochs = 20 # Number of time we procces the entire dataset\n",
    "batch_size = 16 # Number of images feeded at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "805bef231f3f9237172fe564ecd6586c8cd656bd"
   },
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8528318adfc90bcfbf1148b818ccf85dffd2a23e"
   },
   "source": [
    "### Create Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the Keras model and add some layers in order to create our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46a2e630a0cd7409e3fea068c24da29138d5b1ce"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3058007ead9f68d02f4c5e37215973265ff08f85"
   },
   "source": [
    "### Check information about the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e46ec3381202bb48c4b5b8757ae216d3419fa461"
   },
   "outputs": [],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f8ad81e7e7fbaf8227caed6560c2eb6d0165d8d7"
   },
   "outputs": [],
   "source": [
    "model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a377c5e20a51d28d97803c261243ae024fa9305b"
   },
   "outputs": [],
   "source": [
    "model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aaaed230c5eccc5d0e902156620d4cf765eea513"
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the loss, optimizer and metrics that will be used as improvement goals for the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b265d352b0452be0932a3f88dad1799aa863bb22"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4cc666baf4aee1d9dd5b271433492fe49ed7a091"
   },
   "source": [
    "### Upload images from the different sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2554b9e92e24b54bd81b9e7bcdfc1020f1b2d013"
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b91d7ce6e027528166d0c3d57a0d27ecf91e202"
   },
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e03c9d64258481f6219088322d415148be92d524"
   },
   "outputs": [],
   "source": [
    "# Process the train data set\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c949cb908a73cd619e98e2e7681fdedd988e0630"
   },
   "outputs": [],
   "source": [
    "# Process the test data set\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7273a0f54ce7c7eb42807b95a356574281bf67f8",
    "tags": []
   },
   "source": [
    "### Fit the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose between CPU and GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose to use either GPU or CPU. Uncomment the *device_path=\"/cpu:0\"* line if you want to force tensorflow to use CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU\n",
    "device_path=\"/gpu:0\"\n",
    "# CPU\n",
    "# device_path=\"/cpu:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training the model, you can open the Grafana instance and observe the different dashboards about the resource consumption.  \n",
    "Here is the [GPU usage dashboard](https://grafana-route-grafana.apps.sno-nvidia-p6.redhat.hpecic.net/d/51c4ef955d49b81689012770a4b1791ba80e9c7a/nvidia-dcgm-exporter-dashboard?orgId=1)  \n",
    "Here is the [CPU usage dashboard](https://grafana-route-grafana.apps.sno-nvidia-p6.redhat.hpecic.net/d/4ccbbd05fa2622168c09e3b8b92194d2f5825d95/kubernetes-compute-resources-pod?orgId=1&refresh=10s)  \n",
    "On both dashboard you can check the *Utilization* graph.  \n",
    "Note that as some other graph values are calculated on a 5m range, you need to wait a bit after started trainning the model before the peak appears."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "Now we can train the model. Note that it will take around 20min to complete using GPU and around 33min to complete using CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f308ed21aa10578b5e28426c739f9da842b5de0"
   },
   "outputs": [],
   "source": [
    "with tf.device(device_path):\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "afcd3112828276f65d79b8bd6ae86c8bc190791b"
   },
   "outputs": [],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(test_generator)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "When you will finish the lab please run the following commands to cleanup and preserve comput resources. CAUTION, this will delete all your notebooks and the kernel variables containing your model.\n",
    "\n",
    "- Please delete the kernel by clicking Kernel->Shut Down Kernel\n",
    "- Please remove your personnal folder by opening a new terminal (File->New->Terminal) and run *rm -rf /opt/app-root/src/notebooks/<FOLDER_NAME>* where FOLDER_NAME is the name of your personnal directory. This will erase all the content of your directory so please download or push your work if needed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
